{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In our company, Data Scientists have been asked to identify tourists behaviors and called on the Data Engineers to clean, process and develop data model (star schema) that would be the starting point of long-term project that will allow them to establish patterns between the cities that non-immigrants visited. We will create dimension and fact tables and save them as parquet files for star schema model.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import glob\n",
    "import configparser\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id,count,when,date_format\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear,first,lower\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import IntegerType,LongType,StructType,StructField,StringType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "I94 Immigration Data: This data comes from the US National Tourism and Trade Office. Though this data has many fields but we will use only below fields:\n",
    "\n",
    "1) I94YR - Year of admission\n",
    "\n",
    "2) I94RES - 3 digit code of nationality\n",
    "\n",
    "3) I94PORT - 3 character code of destination USA city\n",
    "\n",
    "4) DEPDATE - Departure data in US\n",
    "\n",
    "5) I94BIR - Age of non-immigrant (in years)\n",
    "\n",
    "6) I94VISA - Visa code (1=Business,2=Pleasure,3=Student)\n",
    "\n",
    "7) GENDER - Gender of non-immigrant\n",
    "\n",
    "8) COUNT - Used for summary statistics\n",
    "\n",
    "9) I94MODE - Mode of travel\n",
    "\n",
    "10) VISTYPE - Class of admission\n",
    "\n",
    "11) ADMNUM - Admission number\n",
    "\n",
    "U.S. City Demographic Data: This data comes from OpenSoft\n",
    "\n",
    "1) City\n",
    "\n",
    "2) Male Population\n",
    "\n",
    "3) Female Population\n",
    "\n",
    "4) Median Age\n",
    "\n",
    "5) Total Population\n",
    "\n",
    "6) Foreign-Born\n",
    "\n",
    "7) State Code\n",
    "\n",
    "8) Race\n",
    "\n",
    "9) Count\n",
    "\n",
    "The airport codes: This may refer to either IATA airport code, a three-letter code which is used in passenger reservation, ticketing and baggage-handling systems, or the ICAO airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identifying data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Documenting steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Reading the config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "AWS_ACCESS_KEY_ID     = config.get('AWS', 'AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = config.get('AWS', 'AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating the Spark Session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.2\") \\\n",
    "        .config(\"fs.s3a.access.key\", AWS_ACCESS_KEY_ID) \\\n",
    "        .config(\"fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading City data\n",
    "df_city_temp=spark.read.csv(\"./us-cities-demographics.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first record of City Dataset\n",
    "df_city_temp.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n"
     ]
    }
   ],
   "source": [
    "#Displaying the number of records\n",
    "print(df_city_temp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|        City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+------------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|Saint George| Utah|      37.3|          38732|            41475|           80207|              4443|        4824|                  2.81|        UT|Black or African-...| 1376|\n",
      "|Saint George| Utah|      37.3|          38732|            41475|           80207|              4443|        4824|                  2.81|        UT|  Hispanic or Latino|10829|\n",
      "|Saint George| Utah|      37.3|          38732|            41475|           80207|              4443|        4824|                  2.81|        UT|               Asian| 1649|\n",
      "|Saint George| Utah|      37.3|          38732|            41475|           80207|              4443|        4824|                  2.81|        UT|American Indian a...| 2406|\n",
      "|Saint George| Utah|      37.3|          38732|            41475|           80207|              4443|        4824|                  2.81|        UT|               White|71915|\n",
      "+------------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets explore further and check the records for one city. We see that there are duplicates due to Race Column\n",
    "df_city_temp.filter(df_city_temp.City=='Saint George').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema of city dataframe\n",
    "df_city_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of duplicates rows = 0\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of duplicate rows (if any)\n",
    "duplicates = df_city_temp.count() - df_city_temp.dropDuplicates().count()\n",
    "print(f\"no of duplicates rows = {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race|Count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                13|          13|                    16|         0|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of Null values in all the fields in the city dataset\n",
    "df_city_null = df_city_temp.select([count(when(col(c).isNull(),c)).alias(c) for c in df_city_temp.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|   Male Population| Female Population|Number of Veterans|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              2888|              2888|              2878|\n",
      "|   mean| 97328.42624653739|101769.63088642659| 9367.832522585128|\n",
      "| stddev|216299.93692873296|231564.57257148277| 13211.21992386408|\n",
      "|    min|            100135|            100260|             10001|\n",
      "|    max|             99967|             99430|              9988|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying some high level statistics of the columns with Null Values\n",
    "df_city_temp.describe('Male Population','Female Population','Number of Veterans').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(City='Silver Spring', State='Maryland', Male Population='40601', Female Population='41862', Total Population='82463', Race='Hispanic or Latino', Count='25924')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting columns of our interest from df_city\n",
    "city_columns=['City','State','Male Population','Female Population','Total Population','Race','Count']\n",
    "# Creating a new data frame from city dataframe\n",
    "df_city = df_city_temp.select(city_columns)\n",
    "#Displaying a sample record\n",
    "df_city.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We will clean this dataframe further and try to remove the duplicates with loosing any information\n",
    "df_city_race = df_city.select('City','State','Race','Count').groupBy('City','State').pivot('Race').agg(first('Count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns from df_city_temp\n",
    "df_city_temp = df_city_temp.drop(\"Number of Veterans\").drop(\"Race\").drop(\"Count\").drop('Median Age').drop(\"Foreign-born\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We will join df_city_temp dataframe with df_city_race to denormalize the data\n",
    "city = df_city_temp.join(df_city_race,[\"City\",\"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We will join df_city_temp dataframe with df_city_race to denormalize the data\n",
    "city = city.select(\"City\",\"State\",col(\"Male Population\").alias(\"Male_Population\"),\n",
    "                     col(\"Female Population\").alias(\"Female_Population\"),col(\"Total Population\").alias(\"Total_Population\"),\n",
    "                     col(\"State Code\").alias(\"State_Code\"), \n",
    "                     col(\"American Indian and Alaska Native\").alias(\"Native_P\"),\n",
    "                     col(\"Asian\").alias(\"Asian_P\"),\n",
    "                     col(\"Black or African-American\").alias(\"African_P\"),\n",
    "                     col(\"Hispanic or Latino\").alias(\"Latino_P\"),\n",
    "                     col(\"White\").alias(\"White_P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+---------------+-----------------+----------------+----------+--------+-------+---------+--------+-------+\n",
      "|                City|         State|Male_Population|Female_Population|Total_Population|State_Code|Native_P|Asian_P|African_P|Latino_P|White_P|\n",
      "+--------------------+--------------+---------------+-----------------+----------------+----------+--------+-------+---------+--------+-------+\n",
      "|          Cincinnati|          Ohio|         143654|           154883|          298537|        OH|    3362|   7633|   133430|    9121| 162245|\n",
      "|         Kansas City|        Kansas|          74606|            76655|          151261|        KS|    2749|   7301|    40177|   44342|  96113|\n",
      "|           Lynchburg|      Virginia|          38614|            41198|           79812|        VA|    1024|   2910|    23271|    2689|  53727|\n",
      "|              Auburn|    Washington|          36837|            39743|           76580|        WA|    3042|  12341|     4032|   10836|  58293|\n",
      "|              Dayton|          Ohio|          66631|            73966|          140597|        OH|    2010|   1885|    57280|    4945|  86016|\n",
      "|Louisville/Jeffer...|      Kentucky|         298451|           316938|          615389|        KY|    4585|  18601|   151256|   28712| 456451|\n",
      "|              Austin|         Texas|         475718|           456122|          931840|        TX|   10890|  78916|    81861|  327680| 708171|\n",
      "|           Camarillo|    California|          31941|            35682|           67623|        CA|     742|   7198|     1219|   16186|  59702|\n",
      "|          Pittsburgh|  Pennsylvania|         149690|           154695|          304385|        PA|    2689|  21227|    82248|    9266| 208863|\n",
      "|              Upland|    California|          36226|            40221|           76447|        CA|    1068|   9182|     5717|   30787|  46704|\n",
      "|            Columbus|          Ohio|         413981|           435086|          849067|        OH|   11496|  48974|   256764|   46855| 549468|\n",
      "|          High Point|North Carolina|          51751|            58077|          109828|        NC|    1181|  11060|    39369|   11446|  58004|\n",
      "|         New Bedford| Massachusetts|          43793|            51166|           94959|        MA|     346|   1811|     8890|   18336|  63938|\n",
      "|       Newport Beach|    California|          43161|            43970|           87131|        CA|     423|  10017|     null|    8127|  74814|\n",
      "|             Shawnee|        Kansas|          32313|            32745|           65058|        KS|     485|   3093|     7296|    4864|  55883|\n",
      "|          Sugar Land|         Texas|          43889|            44240|           88129|        TX|    null|  33469|     8993|    7835|  44555|\n",
      "|            Appleton|     Wisconsin|          37217|            38038|           75255|        WI|     835|   5561|     3407|    5139|  64674|\n",
      "|        Lehigh Acres|       Florida|          57856|            61624|          119480|        FL|    1675|   1853|    29998|   42092|  86328|\n",
      "|             Livonia|      Michigan|          45369|            49264|           94633|        MI|     445|   2719|     4633|    1772|  87383|\n",
      "|              Newton| Massachusetts|          41985|            46824|           88809|        MA|     244|  15666|     2925|    4790|  69380|\n",
      "+--------------------+--------------+---------------+-----------------+----------------+----------+--------+-------+---------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying city dataframe\n",
    "city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Total_Population: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Male_Pop: integer (nullable = true)\n",
      " |-- Female_Pop: integer (nullable = true)\n",
      " |-- Total_Pop: integer (nullable = true)\n",
      " |-- Native_Pop: integer (nullable = true)\n",
      " |-- Asian_Pop: integer (nullable = true)\n",
      " |-- African_Pop: integer (nullable = true)\n",
      " |-- Latino_Pop: integer (nullable = true)\n",
      " |-- White_Pop: integer (nullable = true)\n",
      "\n",
      "+--------------------+--------------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "|                City|         State|Total_Population|State_Code|Male_Pop|Female_Pop|Total_Pop|Native_Pop|Asian_Pop|African_Pop|Latino_Pop|White_Pop|\n",
      "+--------------------+--------------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "|          Cincinnati|          Ohio|          298537|        OH|  143654|    154883|   298537|      3362|     7633|     133430|      9121|   162245|\n",
      "|         Kansas City|        Kansas|          151261|        KS|   74606|     76655|   151261|      2749|     7301|      40177|     44342|    96113|\n",
      "|           Lynchburg|      Virginia|           79812|        VA|   38614|     41198|    79812|      1024|     2910|      23271|      2689|    53727|\n",
      "|              Auburn|    Washington|           76580|        WA|   36837|     39743|    76580|      3042|    12341|       4032|     10836|    58293|\n",
      "|              Dayton|          Ohio|          140597|        OH|   66631|     73966|   140597|      2010|     1885|      57280|      4945|    86016|\n",
      "|Louisville/Jeffer...|      Kentucky|          615389|        KY|  298451|    316938|   615389|      4585|    18601|     151256|     28712|   456451|\n",
      "|              Austin|         Texas|          931840|        TX|  475718|    456122|   931840|     10890|    78916|      81861|    327680|   708171|\n",
      "|           Camarillo|    California|           67623|        CA|   31941|     35682|    67623|       742|     7198|       1219|     16186|    59702|\n",
      "|          Pittsburgh|  Pennsylvania|          304385|        PA|  149690|    154695|   304385|      2689|    21227|      82248|      9266|   208863|\n",
      "|              Upland|    California|           76447|        CA|   36226|     40221|    76447|      1068|     9182|       5717|     30787|    46704|\n",
      "|            Columbus|          Ohio|          849067|        OH|  413981|    435086|   849067|     11496|    48974|     256764|     46855|   549468|\n",
      "|          High Point|North Carolina|          109828|        NC|   51751|     58077|   109828|      1181|    11060|      39369|     11446|    58004|\n",
      "|         New Bedford| Massachusetts|           94959|        MA|   43793|     51166|    94959|       346|     1811|       8890|     18336|    63938|\n",
      "|       Newport Beach|    California|           87131|        CA|   43161|     43970|    87131|       423|    10017|       null|      8127|    74814|\n",
      "|             Shawnee|        Kansas|           65058|        KS|   32313|     32745|    65058|       485|     3093|       7296|      4864|    55883|\n",
      "|          Sugar Land|         Texas|           88129|        TX|   43889|     44240|    88129|      null|    33469|       8993|      7835|    44555|\n",
      "|            Appleton|     Wisconsin|           75255|        WI|   37217|     38038|    75255|       835|     5561|       3407|      5139|    64674|\n",
      "|        Lehigh Acres|       Florida|          119480|        FL|   57856|     61624|   119480|      1675|     1853|      29998|     42092|    86328|\n",
      "|             Livonia|      Michigan|           94633|        MI|   45369|     49264|    94633|       445|     2719|       4633|      1772|    87383|\n",
      "|              Newton| Massachusetts|           88809|        MA|   41985|     46824|    88809|       244|    15666|       2925|      4790|    69380|\n",
      "+--------------------+--------------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will join df_city_temp dataframe with df_city_race to denormalize the data\n",
    "city = city.withColumn(\"Male_Pop\",city.Male_Population.cast(IntegerType()))\\\n",
    "                      .withColumn(\"Female_Pop\",city.Female_Population.cast(IntegerType()))\\\n",
    "                      .withColumn(\"Total_Pop\",city.Total_Population.cast(IntegerType()))\\\n",
    "                      .withColumn(\"Native_Pop\",city.Native_P.cast(IntegerType()))\\\n",
    "                      .withColumn(\"Asian_Pop\",city.Asian_P.cast(IntegerType()))\\\n",
    "                      .withColumn(\"African_Pop\",city.African_P.cast(IntegerType()))\\\n",
    "                      .withColumn(\"Latino_Pop\",city.Latino_P.cast(IntegerType()))\\\n",
    "                      .withColumn(\"White_Pop\",city.White_P.cast(IntegerType()))\n",
    "drop_cols=['Male_Population','Female_Population','Total Population','Native_P','Asian_P','African_P',\n",
    "          'Latino_P','White_P']\n",
    "city = city.drop(*drop_cols)\n",
    "city.printSchema()\n",
    "city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "|   City|     State|Total_Population|State_Code|Male_Pop|Female_Pop|Total_Pop|Native_Pop|Asian_Pop|African_Pop|Latino_Pop|White_Pop|\n",
      "+-------+----------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "|Ontario|California|          171200|        CA|   85059|     86141|   171200|      4304|    14313|      12900|    118292|    74765|\n",
      "+-------+----------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking a sample record of a random city\n",
    "city.filter(city.City=='Ontario').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Writing this transformed dataframe to Parquet files partitioned by State\n",
    "city.write.partitionBy('State').parquet(os.path.join('city_data','cities.parquet'),'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Reading airport data\n",
    "df_airport=spark.read.csv(\"airport-codes_csv.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ident='00A', type='heliport', name='Total Rf Heliport', elevation_ft='11', continent='NA', iso_country='US', iso_region='US-PA', municipality='Bensalem', gps_code='00A', iata_code=None, local_code='00A', coordinates='-74.93360137939453, 40.07080078125')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first record of Airport Dataset\n",
    "df_airport.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55075\n"
     ]
    }
   ],
   "source": [
    "#Displaying the number of records\n",
    "print(df_airport.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema of airport dataframe\n",
    "df_airport.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of duplicates rows = 0\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of duplicate rows (if any)\n",
    "duplicates = df_airport.count() - df_airport.dropDuplicates().count()\n",
    "print(f\"no of duplicates rows = {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "|ident|type|name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|coordinates|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "|    0|   0|   0|        7006|        0|          0|         0|        5676|   14045|    45886|     26389|          0|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of Null values in all the fields in the airport dataset\n",
    "df_airport_null = df_airport.select([count(when(col(c).isNull(),c)).alias(c) for c in df_airport.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(type='heliport', name='Total Rf Heliport', iso_country='US', iso_region='US-PA', municipality='Bensalem')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting columns of our interest from df_airport\n",
    "airport_columns=['type','name','iso_country','iso_region','municipality']\n",
    "# Creating a new data frame from airport dataframe\n",
    "df_airport = df_airport.select(airport_columns)\n",
    "#Displaying sample record from airport dataframe\n",
    "df_airport.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Writing this transformed dataframe to Parquet files partitioned by type\n",
    "df_airport.write.partitionBy('type').parquet(os.path.join('airport_data','airport.parquet'),'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading i94 sample data\n",
    "df_i94=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing i94 dataframe schema\n",
    "df_i94.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of duplicates rows = 0\n",
      "no of rows = 3096313\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of duplicate rows (if any)\n",
    "duplicates = df_i94.count() - df_i94.dropDuplicates().count()\n",
    "print(f\"no of duplicates rows = {duplicates}\")\n",
    "print(f\"no of rows = {df_i94.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of Null values in all the fields in the city dataset\n",
    "df_i94.select([count(when(col(c).isNull(),c)).alias(c) for c in df_i94.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Casting the values appropriately\n",
    "df_i94=df_i94.select(col(\"i94res\").cast(IntegerType()),col(\"i94port\"),\n",
    "                           col(\"arrdate\").cast(IntegerType()),\n",
    "                           col(\"i94mode\").cast(IntegerType()),col(\"depdate\").cast(IntegerType()),\n",
    "                           col(\"i94bir\").cast(IntegerType()),col(\"i94visa\").cast(IntegerType()), \n",
    "                           col(\"count\").cast(IntegerType()),\n",
    "                           col(\"gender\"),col(\"admnum\").cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(i94res=438, i94port='LOS', arrdate=20574, i94mode=1, depdate=20582, i94bir=40, i94visa=1, count=1, gender='F', admnum=94953870030)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying a sample record from i94 dataframe\n",
    "df_i94.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Admission number is supposed to be unique\n",
    "df_i94 = df_i94.dropDuplicates(['admnum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075579"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of rows in i94 dataframe now\n",
    "df_i94.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read port_list text file\n",
    "i94_port_df = pd.read_csv('./data/port_list.txt',sep='=',names=['id','port'])\n",
    "\n",
    "# Remove whitespaces and single quotes\n",
    "i94_port_df['id']=i94_port_df['id'].str.strip().str.replace(\"'\",'')\n",
    "\n",
    "# Create two columns from i94port string: port_city and port_addr\n",
    "# also remove whitespaces and single quotes\n",
    "i94_port_df['portcity'], i94_port_df['portstate']=i94_port_df['port'].str.strip().str.replace(\"'\",'').str.strip().str.split(',',1).str\n",
    "\n",
    "# Remove more whitespace from port_addr\n",
    "i94_port_df['portstate']=i94_port_df['portstate'].str.strip()\n",
    "\n",
    "# Drop port column and keep the two new columns: port_city and port_addr\n",
    "i94_port_df.drop(columns =['port'], inplace = True)\n",
    "\n",
    "# Convert pandas dataframe to list (objects which had single quotes removed automatically become string again with single quotes)\n",
    "i94_port_data=i94_port_df.values.tolist()\n",
    "i94_port_df.head()\n",
    "i94port_schema = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('portcity', StringType(), True),\n",
    "    StructField('portstate', StringType(), True)\n",
    "])\n",
    "i94port=spark.createDataFrame(i94_port_data, i94port_schema)\n",
    "i94port.write.mode('overwrite').parquet('data/i94port.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating list for mode of entry\n",
    "i94_mode=[[1,'Air'],[2,'Sea'],[3,'Land'],[9,'Not Reported']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating list for mode of entry\n",
    "i94_mode_df=spark.createDataFrame(i94_mode)\n",
    "i94_mode_df.write.mode('overwrite').parquet('data/i94_mode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading text file for countries\n",
    "i94res_df = pd.read_csv('data/country_list.txt',sep='=',names=['id','country'])\n",
    "# Remove whitespaces and single quotes\n",
    "i94res_df['country']=i94res_df['country'].str.replace(\"'\",'').str.strip()\n",
    "# Convert pandas dataframe to list\n",
    "i94res_data=i94res_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Converting list to spark dataframe\n",
    "i94res_schema = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('country', StringType(), True)\n",
    "])\n",
    "i94res=spark.createDataFrame(i94res_data, i94res_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating parquet file\n",
    "i94res.write.mode('overwrite').parquet('data/i94res.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating dataframe for visa type\n",
    "i94visa_data = [[1, 'Business'], [2, 'Pleasure'], [3, 'Student']]\n",
    "i94visa=spark.createDataFrame(i94visa_data)\n",
    "i94visa.write.mode('overwrite').parquet('./data/i94visa.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Joining i94 dataframe with i94port dataframe\n",
    "df_i94=df_i94.join(i94port,df_i94.i94port==i94port.id,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---+--------+---------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum| id|portcity|portstate|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---+--------+---------+\n",
      "|   135|    BGM|  20556|      1|  20585|    68|      1|    1|     M|93334314430|BGM|  BANGOR|       ME|\n",
      "|   117|    BGM|  20563|      1|  20604|    57|      1|    1|     M|93957147230|BGM|  BANGOR|       ME|\n",
      "|   135|    BGM|  20565|      1|  20569|    58|      1|    1|     M|56546314033|BGM|  BANGOR|       ME|\n",
      "|   111|    BGM|  20563|      1|  20567|    47|      1|    1|     M|93951228330|BGM|  BANGOR|       ME|\n",
      "|   111|    BGM|  20574|      1|  20577|    34|      1|    1|     M|95002968630|BGM|  BANGOR|       ME|\n",
      "|   116|    BGM|  20545|      1|  20547|    68|      1|    1|     M|92504949230|BGM|  BANGOR|       ME|\n",
      "|   117|    BGM|  20560|      1|  20561|    49|      1|    1|     M|93697916730|BGM|  BANGOR|       ME|\n",
      "|   135|    BGM|  20559|      1|  20560|    50|      1|    1|     M|93610988230|BGM|  BANGOR|       ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    56|      2|    1|     M|93924595530|BGM|  BANGOR|       ME|\n",
      "|   297|    BGM|  20574|      1|   null|    63|      1|    1|     F|94990659630|BGM|  BANGOR|       ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    71|      2|    1|     M|93924632130|BGM|  BANGOR|       ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    45|      2|    1|     F|93924444230|BGM|  BANGOR|       ME|\n",
      "|   112|    BGM|  20545|      1|  20546|    44|      1|    1|     M|92446767530|BGM|  BANGOR|       ME|\n",
      "|   135|    BGM|  20547|      1|  20557|    26|      1|    1|     M|92664269630|BGM|  BANGOR|       ME|\n",
      "|   135|    BGM|  20556|      1|  20557|    63|      1|    1|     M|93334238330|BGM|  BANGOR|       ME|\n",
      "|   140|    BGM|  20573|      1|   null|    40|      2|    1|     F|59443385033|BGM|  BANGOR|       ME|\n",
      "|   582|    BGM|  20545|      1|  20546|    41|      1|    1|     M|92480807030|BGM|  BANGOR|       ME|\n",
      "|   104|    BGM|  20556|      1|  20567|    43|      1|    1|     M|93338754830|BGM|  BANGOR|       ME|\n",
      "|   112|    BGM|  20566|      1|  20581|    45|      1|    1|     M|94264768730|BGM|  BANGOR|       ME|\n",
      "|   111|    BGM|  20563|      1|  20567|    43|      1|    1|     M|93951767330|BGM|  BANGOR|       ME|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying a record after join\n",
    "df_i94.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropping off id column\n",
    "df_i94 = df_i94.drop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+--------+---------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|portcity|portstate|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+--------+---------+\n",
      "|   135|    BGM|  20556|      1|  20585|    68|      1|    1|     M|93334314430|  BANGOR|       ME|\n",
      "|   117|    BGM|  20563|      1|  20604|    57|      1|    1|     M|93957147230|  BANGOR|       ME|\n",
      "|   135|    BGM|  20565|      1|  20569|    58|      1|    1|     M|56546314033|  BANGOR|       ME|\n",
      "|   111|    BGM|  20563|      1|  20567|    47|      1|    1|     M|93951228330|  BANGOR|       ME|\n",
      "|   111|    BGM|  20574|      1|  20577|    34|      1|    1|     M|95002968630|  BANGOR|       ME|\n",
      "|   116|    BGM|  20545|      1|  20547|    68|      1|    1|     M|92504949230|  BANGOR|       ME|\n",
      "|   117|    BGM|  20560|      1|  20561|    49|      1|    1|     M|93697916730|  BANGOR|       ME|\n",
      "|   135|    BGM|  20559|      1|  20560|    50|      1|    1|     M|93610988230|  BANGOR|       ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    56|      2|    1|     M|93924595530|  BANGOR|       ME|\n",
      "|   297|    BGM|  20574|      1|   null|    63|      1|    1|     F|94990659630|  BANGOR|       ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    71|      2|    1|     M|93924632130|  BANGOR|       ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    45|      2|    1|     F|93924444230|  BANGOR|       ME|\n",
      "|   112|    BGM|  20545|      1|  20546|    44|      1|    1|     M|92446767530|  BANGOR|       ME|\n",
      "|   135|    BGM|  20547|      1|  20557|    26|      1|    1|     M|92664269630|  BANGOR|       ME|\n",
      "|   135|    BGM|  20556|      1|  20557|    63|      1|    1|     M|93334238330|  BANGOR|       ME|\n",
      "|   140|    BGM|  20573|      1|   null|    40|      2|    1|     F|59443385033|  BANGOR|       ME|\n",
      "|   582|    BGM|  20545|      1|  20546|    41|      1|    1|     M|92480807030|  BANGOR|       ME|\n",
      "|   104|    BGM|  20556|      1|  20567|    43|      1|    1|     M|93338754830|  BANGOR|       ME|\n",
      "|   112|    BGM|  20566|      1|  20581|    45|      1|    1|     M|94264768730|  BANGOR|       ME|\n",
      "|   111|    BGM|  20563|      1|  20567|    43|      1|    1|     M|93951767330|  BANGOR|       ME|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying i94 dataframe\n",
    "df_i94.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Joining i94 dataframe with city dataframe\n",
    "i94_city= df_i94.join(city,(lower(df_i94.portcity)==lower(city.City)) & (lower(df_i94.portstate)==lower(city.State)),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropping off City and State columuns from the joined dataframe\n",
    "i94_city=i94_city.drop(\"City\",\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+--------+---------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|portcity|portstate|Total_Population|State_Code|Male_Pop|Female_Pop|Total_Pop|Native_Pop|Asian_Pop|African_Pop|Latino_Pop|White_Pop|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+--------+---------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "|   582|    ONT|  20553|      1|  20591|    69|      2|    1|     M|  748039585| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20546|      1|  20549|    30|      2|    1|     F|92521757230| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20561|      1|  20596|    68|      2|    1|     F|93749540630| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20562|      1|   null|    57|      2|    1|     F|93845651230| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20562|      1|  20618|    71|      2|    1|     F|93845850130| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20566|      1|   null|    64|      2|    1|     F|94188047330| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20568|      1|  20585|     3|      2|    1|     M|94386161030| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20572|      1|  20575|    58|      1|    1|     F|94717144630| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20561|      1|  20563|    21|      2|    1|     F|93749484730| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20547|      1|  20560|    63|      2|    1|     M|92610425530| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20560|      1|  20575|    71|      2|    1|     M|93659987830| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20561|      1|  20651|    72|      2|    1|     F|93749567130| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20565|      1|   null|    63|      2|    1|     F|94088362630| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20565|      1|  20591|    58|      2|    1|     F|94088701830| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20547|      1|   null|    68|      2|    1|     F|92610221030| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20553|      1|  20611|    80|      2|    1|     F|93074527430| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20553|      1|  20568|     9|      2|    1|     F|93074618130| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20554|      1|  20584|    53|      2|    1|     F|93157201630| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20556|      1|  20616|    24|      2|    1|     M|93308359030| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "|   582|    ONT|  20558|      1|  20565|    70|      2|    1|     M|93457776630| ONTARIO|       CA|            null|      null|    null|      null|     null|      null|     null|       null|      null|     null|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+--------+---------+----------------+----------+--------+----------+---------+----------+---------+-----------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying the joined dataframe\n",
    "i94_city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Converting SAS date to datetime\n",
    "get_date = udf(lambda x: (datetime.datetime(1960, 1, 1).date() + datetime.timedelta(x)).isoformat() if x else None)\n",
    "i94_city = i94_city.withColumn(\"arrival_date\", get_date(i94_city.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(i94res=582, i94port='ONT', arrdate=20553, i94mode=1, depdate=20591, i94bir=69, i94visa=2, count=1, gender='M', admnum=748039585, portcity='ONTARIO', portstate='CA', Total_Population=None, State_Code=None, Male_Pop=None, Female_Pop=None, Total_Pop=None, Native_Pop=None, Asian_Pop=None, African_Pop=None, Latino_Pop=None, White_Pop=None, arrival_date='2016-04-09')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying sample record\n",
    "i94_city.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating dataframe for date dimensions\n",
    "i94date=i94_city.select(col('arrdate').alias('arrival_sasdate'),\n",
    "                                   col('arrival_date').alias('arrivaldate'),\n",
    "                                   date_format('arrival_date','M').alias('arrival_month'),\n",
    "                                   date_format('arrival_date','E').alias('arrival_dayofweek'), \n",
    "                                   date_format('arrival_date', 'y').alias('arrival_year'), \n",
    "                                   date_format('arrival_date', 'd').alias('arrival_day'),\n",
    "                                  date_format('arrival_date','w').alias('arrival_weekofyear')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-------------+-----------------+------------+-----------+------------------+\n",
      "|arrival_sasdate|arrivaldate|arrival_month|arrival_dayofweek|arrival_year|arrival_day|arrival_weekofyear|\n",
      "+---------------+-----------+-------------+-----------------+------------+-----------+------------------+\n",
      "|          20558| 2016-04-14|            4|              Thu|        2016|         14|                16|\n",
      "|          20563| 2016-04-19|            4|              Tue|        2016|         19|                17|\n",
      "|          20547| 2016-04-03|            4|              Sun|        2016|          3|                15|\n",
      "|          20559| 2016-04-15|            4|              Fri|        2016|         15|                16|\n",
      "|          20554| 2016-04-10|            4|              Sun|        2016|         10|                16|\n",
      "|          20557| 2016-04-13|            4|              Wed|        2016|         13|                16|\n",
      "|          20551| 2016-04-07|            4|              Thu|        2016|          7|                15|\n",
      "|          20561| 2016-04-17|            4|              Sun|        2016|         17|                17|\n",
      "|          20564| 2016-04-20|            4|              Wed|        2016|         20|                17|\n",
      "|          20568| 2016-04-24|            4|              Sun|        2016|         24|                18|\n",
      "|          20572| 2016-04-28|            4|              Thu|        2016|         28|                18|\n",
      "|          20571| 2016-04-27|            4|              Wed|        2016|         27|                18|\n",
      "|          20570| 2016-04-26|            4|              Tue|        2016|         26|                18|\n",
      "|          20552| 2016-04-08|            4|              Fri|        2016|          8|                15|\n",
      "|          20549| 2016-04-05|            4|              Tue|        2016|          5|                15|\n",
      "|          20553| 2016-04-09|            4|              Sat|        2016|          9|                15|\n",
      "|          20556| 2016-04-12|            4|              Tue|        2016|         12|                16|\n",
      "|          20567| 2016-04-23|            4|              Sat|        2016|         23|                17|\n",
      "|          20566| 2016-04-22|            4|              Fri|        2016|         22|                17|\n",
      "|          20548| 2016-04-04|            4|              Mon|        2016|          4|                15|\n",
      "+---------------+-----------+-------------+-----------------+------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying date dataframe\n",
    "i94date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Joining date dataframe with i94 dataframe\n",
    "i94_full = i94_city.join(i94date,i94_city.arrdate==i94date.arrival_sasdate,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Displaying i94_full dataframe\n",
    "#i94_full.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing i94 data to parquet files partitioned by year and month\n",
    "i94_full.write.partitionBy('arrival_year','arrival_month').parquet(os.path.join('i94_data','i94.parquet'),'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Displaying schema of i94_full dataframe\n",
    "#i94_full.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Defining the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "We have saved the dimension tables as parquet files and we can implement them on any columnar database in Star Schema model. Star Schema model is a popular model widely used for Data Analysis.\n",
    "\n",
    "![data model](img/i94_data_model.PNG)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Install the required packages and dependencies like pandas, sql functions, os, configparser, Sparksession\n",
    "2. Read US Cities Demo dataset file df_city_temp dataframe\n",
    "3. Create df_city from df_city_temp after selecting the column of interest\n",
    "4. Drop duplicate rows from df_city\n",
    "5. Rename the columns and reduce the number of rows by pivoting using Race column\n",
    "6. Drop the columns which are not required\n",
    "7. Write (and overwrite) transformed City dataset into parquet file partitioned by State\n",
    "8. Read Airport dataset into df_airport\n",
    "9. Select the columns of interest\n",
    "10. Drop the duplicates\n",
    "11. Write transformed airport dataset into parquet files partitioned by airport type\n",
    "12. Read i94 non-immigration dataset to df_i94 dataframe\n",
    "13. Convert numbers to longtype and integertype\n",
    "14. Drop rows which have duplicate admission number as this is suppose to be a unique value\n",
    "15. Read i94port dimension parquet file so we can use it to join with df_i94. This will add i94port city and state columns to df_i94 dataframe\n",
    "16. Drop id column from i94 dataframe\n",
    "17. Join city with df_i94 to get fact table i94_city\n",
    "18. Add iso date format column arrival_date inside the i94_city dataframe by using udf.\n",
    "19. Join i94_city with i94date to create i94_full dataframe.\n",
    "20. Save i94_full to parquet file partitioned by year and month of arrival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Creating the data model\n",
    "Building the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# etl.py will be used to build the data pipeline. Please uncomment line below to execute\n",
    "#%run etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Below data quality checks are performed to ensure the pipeline ran as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File reading successful\n",
      "Transformation went successful\n",
      "File reading successful\n"
     ]
    }
   ],
   "source": [
    "# Data quality checks\n",
    "\n",
    "if df_city.count() > 0:\n",
    "    print('File reading successful')\n",
    "else:\n",
    "    print('Problem with reading file')\n",
    "\n",
    "if city.count() == df_city_race.count():\n",
    "    print('Transformation went successful')\n",
    "else:\n",
    "    print('Some problem with transformation')\n",
    "\n",
    "if df_i94.count() > 0:\n",
    "    print('File reading successful')\n",
    "else:\n",
    "    print('Problem with reading file')\n",
    "    \n",
    "if df_i94.count() == i94_full.count():\n",
    "    print('Transformation went successful')\n",
    "else:\n",
    "    print('Some problem with transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "#### Fact Table - I94 immigration data joined with the city data on i94port Columns:\n",
    "\n",
    "- admnum = admission no coming from i94 data,\n",
    "- i94res = 3 digit code of nationality from i94 non-immigration data,\n",
    "- i94port = 3 character code of destination USA city from i94 non-immigration data,\n",
    "- arrdate = arrival date in the USA from i94 non-immigration data,\n",
    "- i94mode = 1 digit mode of travel from i94 non-immigration data,\n",
    "- depdate = Departure Date from the USA,\n",
    "- i94bir = year of birth,\n",
    "- i94visa = reason for immigration from i94 non-immigration data,\n",
    "- count = used for statistical metrics from i94 non-immigration data,\n",
    "- gender = Non-immigrant sex from i94 non-immigration data,\n",
    "- total_population = Total population of city and state from US cities demographics data,\n",
    "- state_code = State Code from US cities demographics data,\n",
    "- male_pop = Male population of city and state from US cities demographics data,\n",
    "- female_pop = Female population of city and state from US cities demographics data,\n",
    "- native_pop = Aerican Indian population of city and state from US cities demographics data,\n",
    "- asian_pop = Asian population of city and state from US cities demographics data,\n",
    "- african_pop = African population of city and state from US cities demographics data,\n",
    "- latino_pop = Latino population of city and state from US cities demographics data,\n",
    "- white_pop = White population of city and state from US cities demographics data\n",
    "- arrival_date = Arrival date in datetime format coming from i94 data\n",
    "\n",
    "#### Dimension Table - i94date:\n",
    "- arrival_sasdate = Arrival date in the USA (SAS date field) from i94 non-immigration data,\n",
    "- arrival_date = Arrival date in datetime format derived from from i94 non-immigration data,\n",
    "- arrival_month = Month of arrival coming from i94 non-immigration data,\n",
    "- arrival_year = Year of arrival coming from i94 non-immigration data,\n",
    "- arrival_day = Day of arrival coming from i94 non-immigration data,\n",
    "- arrival_week = Week of arrival coming from i94 non-immigration data,\n",
    "\n",
    "#### Dimension Table - i94res:\n",
    "- id = 3 digit code of nationality from i94 non-immigration data,\n",
    "- country = Country coming from SAS Labels\n",
    "\n",
    "#### Dimension Table - i94mode:\n",
    "- id = 1 digit mode of travel code from i94 non-immigration data\n",
    "- mode_transport = String value coming from SAS Labels\n",
    "\n",
    "#### Dimension Table - i94port:\n",
    "- id = Admission 3 character code of destination USA city,\n",
    "- city = String value of the city code\n",
    "- state = String value of the state code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Project Conclusion\n",
    "* We used opensource Apache PySpark and Python tools that can be easily ported over to cloud such as AWS\n",
    "* If the data were to increase by 100X we will use EMR Cluster on AWS along with S3 for storage.\n",
    "* To run the pipleline on a schedule basis we can leverage the cover of Apache Airflow.\n",
    "* If the database need to be accessed by large number of users then we can load the parquet files to petabyte scale AWS data warehouse solution Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
